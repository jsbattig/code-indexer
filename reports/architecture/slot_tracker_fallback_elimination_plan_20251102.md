# Architectural Plan: Eliminating Slot Tracker Fallback Mechanism
**Date**: November 2, 2025
**Author**: Elite Software Architect
**Priority**: CRITICAL
**Impact**: Daemon Mode UX Parity

## Executive Summary

The current daemon mode progress callback system has a critical architectural flaw where only 4 out of 20 progress callbacks pass `concurrent_files` data, causing 16 callbacks to fall back to RPyC proxy calls on `slot_tracker`. This creates performance degradation, stale data issues, and violates the "no fallbacks" principle. This plan eliminates ALL fallback logic by ensuring every progress callback with `total > 0` passes serializable `concurrent_files` data.

## 1. Problem Statement

### Current Architecture (Problematic)

```
HighThroughputProcessor â†’ progress_callback â†’ Daemon Service â†’ RPyC â†’ CLI Client
                         â†“                     â†“
                    20 total calls         Serialization Layer
                         â†“                     â†“
                 4 with concurrent_files   JSON: concurrent_files âœ“
                16 without concurrent_files RPyC Proxy: slot_tracker âœ—
                         â†“                     â†“
                    CLI Fallback Logic    Performance Issues
```

### Specific Issues

1. **80% Missing Data**: 16 of 20 callbacks don't include `concurrent_files`
2. **RPyC Proxy Overhead**: Fallback to `slot_tracker.get_concurrent_files_data()` causes network latency
3. **Stale Data**: RPyC proxy caching leads to frozen/outdated progress display
4. **Complex Fallback Logic**: Violates "I don't like fallbacks" principle
5. **UX Disparity**: Daemon mode shows stale/incomplete progress vs standalone mode

### Root Cause Analysis

Looking at `high_throughput_processor.py`, the callbacks are categorized as:

**Type A - Setup Messages (total=0)**: Lines 280, 503, 530, 560, 723, 745, 879, 911, 932, 960, 1205, 1220, 1261, 1287, 1359
- Don't need concurrent_files (setup/info messages only)

**Type B - Progress Updates (total>0)**: Lines 419, 462, 519, 670
- **ONLY 4 CALLBACKS** pass concurrent_files (lines 419, 670 have deepcopy workaround)
- Lines 462, 519 pass empty list `concurrent_files=[]`

**Type C - Completion (current=total)**: Line 735
- Missing concurrent_files entirely!

## 2. Current vs Desired Architecture

### Current Flow (Broken)
```
HighThroughputProcessor.process_files_high_throughput()
â”œâ”€â”€ Hash Phase (lines 306-526)
â”‚   â”œâ”€â”€ Line 419: âœ“ concurrent_files via deepcopy(hash_slot_tracker.get_concurrent_files_data())
â”‚   â”œâ”€â”€ Line 462: âœ— concurrent_files=[] (empty!)
â”‚   â””â”€â”€ Line 519: âœ— concurrent_files=[] (empty!)
â”‚
â”œâ”€â”€ Indexing Phase (lines 569-711)
â”‚   â””â”€â”€ Line 670: âœ“ concurrent_files via deepcopy(local_slot_tracker.get_concurrent_files_data())
â”‚
â””â”€â”€ Completion (lines 722-741)
    â””â”€â”€ Line 735: âœ— NO concurrent_files parameter at all!

CLI Daemon Delegation (cli_daemon_delegation.py)
â”œâ”€â”€ Line 755: concurrent_files_json = kwargs.get("concurrent_files_json", "[]")
â”œâ”€â”€ Line 756: concurrent_files = json.loads(concurrent_files_json)
â””â”€â”€ FALLBACK: If empty â†’ tries slot_tracker RPyC proxy (BAD!)
```

### Desired Flow (Fixed)
```
HighThroughputProcessor.process_files_high_throughput()
â”œâ”€â”€ Hash Phase
â”‚   â”œâ”€â”€ Line 419: âœ“ Keep existing deepcopy
â”‚   â”œâ”€â”€ Line 462: âœ“ ADD concurrent_files=copy.deepcopy(hash_slot_tracker.get_concurrent_files_data())
â”‚   â””â”€â”€ Line 519: âœ“ ADD concurrent_files=copy.deepcopy(hash_slot_tracker.get_concurrent_files_data())
â”‚
â”œâ”€â”€ Indexing Phase
â”‚   â””â”€â”€ Line 670: âœ“ Keep existing deepcopy
â”‚
â””â”€â”€ Completion
    â””â”€â”€ Line 735: âœ“ ADD concurrent_files=[] (empty is fine for completion)

Daemon Service (daemon/service.py)
â”œâ”€â”€ Remove slot_tracker from callback kwargs entirely
â””â”€â”€ Always serialize concurrent_files to JSON

CLI Daemon Delegation
â”œâ”€â”€ Remove ALL fallback logic for slot_tracker
â””â”€â”€ Always use concurrent_files from JSON (empty list if missing)
```

## 3. Implementation Plan

### Phase 1: Fix HighThroughputProcessor Callbacks

#### File: `src/code_indexer/services/high_throughput_processor.py`

**Change 1 - Line 462** (Hash phase initial progress):
```python
# BEFORE:
progress_callback(
    0,
    len(files),
    Path(""),
    info=f"0/{len(files)} files (0%) | 0.0 files/s | 0.0 KB/s | 0 threads | ðŸ” Starting hash calculation...",
    concurrent_files=[],  # Empty!
    slot_tracker=hash_slot_tracker,
)

# AFTER:
import copy
progress_callback(
    0,
    len(files),
    Path(""),
    info=f"0/{len(files)} files (0%) | 0.0 files/s | 0.0 KB/s | 0 threads | ðŸ” Starting hash calculation...",
    concurrent_files=copy.deepcopy(hash_slot_tracker.get_concurrent_files_data()),
    slot_tracker=hash_slot_tracker,
)
```

**Change 2 - Line 519** (Hash phase completion):
```python
# BEFORE:
progress_callback(
    len(files),
    len(files),
    Path(""),
    info=f"{len(files)}/{len(files)} files (100%) | {files_per_sec:.1f} files/s | {kb_per_sec:.1f} KB/s | {vector_thread_count} threads | ðŸ” âœ… Hash calculation complete",
    concurrent_files=[],  # Empty!
    slot_tracker=hash_slot_tracker,
)

# AFTER:
import copy
progress_callback(
    len(files),
    len(files),
    Path(""),
    info=f"{len(files)}/{len(files)} files (100%) | {files_per_sec:.1f} files/s | {kb_per_sec:.1f} KB/s | {vector_thread_count} threads | ðŸ” âœ… Hash calculation complete",
    concurrent_files=copy.deepcopy(hash_slot_tracker.get_concurrent_files_data()),
    slot_tracker=hash_slot_tracker,
)
```

**Change 3 - Line 735** (Final completion):
```python
# BEFORE:
progress_callback(
    len(files),  # current = total for 100% completion
    len(files),  # total files
    Path(""),  # Empty path with info = progress bar description update
    info=final_info_msg,
    slot_tracker=local_slot_tracker,  # Missing concurrent_files!
)

# AFTER:
progress_callback(
    len(files),  # current = total for 100% completion
    len(files),  # total files
    Path(""),  # Empty path with info = progress bar description update
    info=final_info_msg,
    concurrent_files=[],  # Empty list for completion (no active files)
    slot_tracker=local_slot_tracker,
)
```

### Phase 2: Remove Slot Tracker from Daemon Serialization

#### File: `src/code_indexer/daemon/service.py`

**Change in `correlated_callback` (lines 227-244)**:
```python
def correlated_callback(current, total, file_path, info="", **cb_kwargs):
    """Progress callback with JSON serialization for concurrent_files."""
    with callback_lock:
        callback_counter[0] += 1
        correlation_id = callback_counter[0]

    # EXISTING: Serialize concurrent_files to JSON
    import json
    concurrent_files = cb_kwargs.get('concurrent_files', [])
    concurrent_files_json = json.dumps(concurrent_files)
    cb_kwargs['concurrent_files_json'] = concurrent_files_json
    cb_kwargs['correlation_id'] = correlation_id

    # NEW: Remove slot_tracker from kwargs before sending to client
    # RPyC proxy objects should never be sent to client
    cb_kwargs.pop('slot_tracker', None)

    # Call actual client callback
    if callback:
        callback(current, total, file_path, info, **cb_kwargs)
```

### Phase 3: Remove Fallback Logic in CLI

#### File: `src/code_indexer/cli.py`

**Change in `update_file_progress_with_concurrent_files` (lines 3517-3566)**:
```python
def update_file_progress_with_concurrent_files(
    current: int, total: int, info: str, concurrent_files=None
):
    """Update file processing with concurrent file tracking."""
    nonlocal display_initialized

    # Initialize Rich Live display on first call
    if not display_initialized:
        rich_live_manager.start_bottom_display()
        display_initialized = True

    # Parse progress info for metrics
    # ... (existing parsing logic) ...

    # REMOVED: No more slot_tracker fallback!
    # OLD CODE TO REMOVE:
    # slot_tracker = None
    # if hasattr(smart_indexer, "slot_tracker"):
    #     slot_tracker = smart_indexer.slot_tracker

    # Update MultiThreadedProgressManager with concurrent files
    # Use empty list if concurrent_files is None (defensive programming)
    progress_manager.update_complete_state(
        current=current,
        total=total,
        files_per_second=files_per_second,
        kb_per_second=kb_per_second,
        active_threads=active_threads,
        concurrent_files=concurrent_files or [],  # Always use provided data
        slot_tracker=None,  # No more slot_tracker in CLI!
        info=info,
    )

    # ... rest of function ...
```

#### File: `src/code_indexer/cli_daemon_delegation.py`

**Change in `progress_callback` (lines 726-794)**:
```python
def progress_callback(current, total, file_path, info="", **kwargs):
    """Progress callback for daemon indexing with Rich Live display."""
    # ... (existing defensive checks) ...

    # Setup messages scroll at top (when total=0)
    if total == 0:
        rich_live_manager.handle_setup_message(info)
        return

    # Deserialize concurrent_files from JSON (NO FALLBACK!)
    import json
    concurrent_files_json = kwargs.get("concurrent_files_json", "[]")
    concurrent_files = json.loads(concurrent_files_json)

    # REMOVED: No more slot_tracker handling!
    # OLD CODE TO REMOVE:
    # slot_tracker = kwargs.get("slot_tracker", None)

    # ... (existing parsing logic) ...

    # Update progress manager (no slot_tracker!)
    progress_manager.update_complete_state(
        current=current,
        total=total,
        files_per_second=files_per_second,
        kb_per_second=kb_per_second,
        active_threads=active_threads,
        concurrent_files=concurrent_files,
        slot_tracker=None,  # Always None in daemon mode
        info=info,
    )

    # ... rest of function ...
```

## 4. Test Strategy

### Unit Tests

1. **Test Concurrent Files Always Present**:
   - Mock progress_callback and verify ALL calls with total>0 have concurrent_files
   - File: `tests/unit/services/test_high_throughput_concurrent_files.py`

2. **Test No RPyC Proxy Leakage**:
   - Verify daemon service never sends slot_tracker in kwargs
   - File: `tests/unit/daemon/test_no_rpyc_proxy_leakage.py`

3. **Test JSON Serialization**:
   - Verify concurrent_files always serializes to valid JSON
   - File: `tests/unit/daemon/test_concurrent_files_json.py`

### Integration Tests

1. **Test Daemon Progress Display**:
   - Index 100+ files via daemon
   - Verify concurrent files display updates in real-time
   - No stale/frozen data
   - File: `tests/integration/daemon/test_progress_display_parity.py`

2. **Test Performance**:
   - Measure callback latency before/after fix
   - Should show significant improvement (no RPyC proxy calls)
   - File: `tests/integration/daemon/test_progress_performance.py`

### Acceptance Criteria

âœ… ALL progress callbacks with total>0 include concurrent_files
âœ… NO slot_tracker parameter sent to client in daemon mode
âœ… NO fallback logic in CLI for missing concurrent_files
âœ… Daemon mode shows identical progress to standalone mode
âœ… No performance regression (faster due to no RPyC proxy calls)
âœ… All existing tests pass

## 5. Edge Cases and Considerations

### Edge Case 1: Empty File List
- When no files to process, concurrent_files should be empty list `[]`
- Never null or undefined

### Edge Case 2: Cancellation During Progress
- Concurrent_files should still be provided during cancellation
- Shows which files were active when cancelled

### Edge Case 3: Phase Transitions
- Hash â†’ Indexing transition: concurrent_files switches from hash_slot_tracker to local_slot_tracker
- Must use correct tracker for each phase

### Edge Case 4: Large File Sets
- Deep copying concurrent_files for 1000+ files
- JSON serialization overhead acceptable (< 10ms for 1000 files)

## 6. Migration and Rollback Plan

### Migration Steps

1. **Deploy in Dev** (Day 1):
   - Apply changes to high_throughput_processor.py
   - Test with small projects

2. **Extended Testing** (Day 2-3):
   - Test with large codebases (10K+ files)
   - Monitor daemon memory usage
   - Verify no performance regression

3. **Production Rollout** (Day 4):
   - Deploy to production
   - Monitor for 24 hours
   - Check logs for any serialization errors

### Rollback Plan

If issues arise:

1. **Immediate Rollback**:
   - Revert high_throughput_processor.py changes
   - Keeps daemon service changes (backward compatible)
   - CLI fallback logic remains removed (works with empty concurrent_files)

2. **Diagnostic Data**:
   - Capture daemon logs
   - Record specific callback invocations that failed
   - Profile JSON serialization performance

3. **Alternative Approach** (if needed):
   - Batch concurrent_files updates (every N callbacks)
   - Use compression for large concurrent_files data
   - Implement client-side caching with invalidation

## 7. Implementation Checklist

- [ ] Fix line 462 in high_throughput_processor.py (hash phase start)
- [ ] Fix line 519 in high_throughput_processor.py (hash phase complete)
- [ ] Fix line 735 in high_throughput_processor.py (final completion)
- [ ] Remove slot_tracker from daemon service callback kwargs
- [ ] Remove slot_tracker fallback in cli.py
- [ ] Remove slot_tracker handling in cli_daemon_delegation.py
- [ ] Add unit test for concurrent_files presence
- [ ] Add integration test for daemon progress parity
- [ ] Update documentation
- [ ] Performance benchmarks before/after

## 8. Expected Outcomes

### Performance Improvements
- **Callback Latency**: 50-100ms â†’ 1-5ms (no RPyC proxy calls)
- **Progress Update Rate**: Real-time updates (no stale data)
- **Network Traffic**: Reduced by 80% (no proxy method calls)

### UX Improvements
- Live concurrent file display in daemon mode
- Accurate thread count reporting
- Smooth progress bar updates
- No frozen/stale progress data

### Code Quality
- Eliminated fallback logic (cleaner architecture)
- Reduced complexity in CLI
- Clear separation of concerns (serialization in daemon only)
- Better testability (no RPyC proxies to mock)

## Conclusion

This architectural fix eliminates a critical flaw in the daemon mode progress system. By ensuring ALL progress callbacks include serializable `concurrent_files` data, we remove the need for fallback logic, eliminate RPyC proxy performance issues, and achieve true UX parity between daemon and standalone modes. The implementation is straightforward, backward compatible, and will significantly improve the user experience.

**Estimated Implementation Time**: 2-3 hours
**Risk Level**: Low (additive changes, backward compatible)
**Priority**: CRITICAL (affects core UX in daemon mode)